{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8beb9a4f-0d22-4d5d-9445-e5514599b314",
   "metadata": {},
   "source": [
    "# Задание 13\n",
    "\n",
    "Дан Марковский Процесс Принятия Решений и таблица полезностей `Q`\n",
    "\n",
    "Нужно подменить ровно одно значение полезности `состояние-действие` так, чтобы жадный алгоритм получил наименьшую дисконтированную награду при коэффициенте дисконтирования $\\gamma = 0.9$\n",
    "\n",
    "BruteForce Emulation: 4/10 баллов\n",
    "\n",
    "Не догадался улучшить, пробуя не только минимизировать лучшее из значений, но и максимизировать хужшее из значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34f3680c-3a45-404f-b48b-0861fc31af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from json import load as json_to_obj\n",
    "from json import dump as obj_to_json\n",
    "\n",
    "data_path = os.path.join('/tf','shared_data','profi-23', '13') + os.path.sep\n",
    "\n",
    "mdps_path = data_path + 'mdps.json'\n",
    "strategy_path = data_path + 'q_tables.json'\n",
    "sample_path = data_path + 'submit.json'\n",
    "submission_path = data_path + 'submission.json'\n",
    "\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        json_obj = json_to_obj(f)\n",
    "    return json_obj\n",
    "\n",
    "\n",
    "def write_json(path, obj):\n",
    "    with open(path, 'w') as f:\n",
    "        obj_to_json(obj, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18be835c-e92a-4689-ad34-f358d9fe6bf3",
   "metadata": {},
   "source": [
    "Список словарей содержит данные о каждом МППР, который определяется состояниями, действиями, вероятностями перехода и вознаграждениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa74d285-b79c-43ce-83bd-af6ef7319f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'0': [{'probability': 1.0, 'next_state': '1', 'reward': 0.33}],\n",
       "  '1': [{'probability': 1.0, 'next_state': '1', 'reward': -0.64}]},\n",
       " '1': {'0': [{'probability': 1.0, 'next_state': '0', 'reward': 0.1}],\n",
       "  '1': [{'probability': 1.0, 'next_state': '0', 'reward': -0.25}]}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdps = read_json(mdps_path)\n",
    "print(len(mdps))\n",
    "mdps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348e95ed-8d2f-424e-9c2c-c3f3e6e6a4dd",
   "metadata": {},
   "source": [
    "Словарь определяющий полезность каждого действия, жадная стратегия на его основе используется для управления системой. Формат состояние -> действие -> полезность.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dcfd65f-1ffc-4589-8a03-f47443e79112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'0': 2.2063543094206666, '1': 1.2363543094206664},\n",
       " '1': {'0': 2.0857188784786, '1': 1.7357188784786}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_tables = read_json(strategy_path)\n",
    "print(len(q_tables))\n",
    "q_tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f88572-b911-4f77-9839-35d17319a391",
   "metadata": {},
   "source": [
    "Список изменений для одной пары состояния-действия каждого МППР, которые необходимо произвести."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8e4d7a-908b-49dd-880d-0ebbaecb8964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'state': '0', 'action': '0', 'value': -1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = read_json(sample_path)\n",
    "print(len(sample))\n",
    "sample[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09e1055-0292-4873-9547-3ffc0fcd6e8a",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "```python\n",
    "def create_dummy_answer(q_table_):\n",
    "    # Выбираем первое состояние словаря и\n",
    "    # присваиваем -1 его самому полезному действию.\n",
    "    state, actions = next(iter(q_table_.items()))\n",
    "    max_action = max(actions, key=actions.get)\n",
    "    return {'state': state, 'action': max_action, 'value': -1}\n",
    "\n",
    "answers = []\n",
    "for q_table in q_tables:\n",
    "    answers.append(create_dummy_answer(q_table))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb4e148-e2a8-43e1-b228-506d86e15523",
   "metadata": {},
   "source": [
    "## BOSSline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca5734d6-eb32-402b-ab6c-bb99b6a47c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices\n",
    "\n",
    "def calc_reward(model, strategy):\n",
    "    total = 0\n",
    "    \n",
    "    for start_state in strategy.keys():\n",
    "        coef = 1\n",
    "        state = start_state\n",
    "        for step in range(4000):\n",
    "            best_action = next(iter(strategy[state]))\n",
    "            \n",
    "            for action in strategy[state].keys():\n",
    "                if strategy[state][action] > strategy[state][best_action]:\n",
    "                    best_action = action\n",
    "\n",
    "            probs = []\n",
    "            for jump in model[state][best_action]:\n",
    "                probs.append(jump['probability'])\n",
    "\n",
    "            jump = choices(model[state][best_action], weights=probs)[0]\n",
    "            \n",
    "            total += coef * jump['reward']\n",
    "            state = jump['next_state']\n",
    "            coef *= 0.9\n",
    "            \n",
    "    return total\n",
    "\n",
    "\n",
    "def create_smart_answer(model, strategy):\n",
    "    best_state = next(iter(strategy))\n",
    "    best_action = next(iter(strategy[best_state]))\n",
    "    new_value = strategy[best_state][best_action]\n",
    "    best_reward = calc_reward(model, strategy)\n",
    "    \n",
    "    for state, actions in strategy.items():\n",
    "        for action, value in actions.items():\n",
    "            saved = value\n",
    "            \n",
    "            strategy[state][action] = -10\n",
    "            reward = calc_reward(model, strategy)\n",
    "            strategy[state][action] = saved\n",
    "            \n",
    "            if reward < best_reward:\n",
    "                best_reward = reward\n",
    "                best_state = state\n",
    "                best_action = action\n",
    "                new_value = -10\n",
    "    return {'state': best_state, 'action': best_action, 'value': new_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffc5b91c-052f-45a0-9d1f-281579580a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da05fab2c6994edca0da986139673fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "answers = []\n",
    "total_tests = len(q_tables)\n",
    "for i in tqdm(range(total_tests)):\n",
    "    answers.append(create_smart_answer(mdps[i], q_tables[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb37ec0a-0570-408b-8d5c-bea801e77a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(submission_path, answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
